## What is load balancer?

A **load balancer** is a device or software component that distributes incoming network traffic across multiple servers or resources to ensure optimal utilization, maximize throughput, minimize response time, and avoid overloading any single server. It enhances the availability, reliability, and scalability of applications.

### **How a Load Balancer Works:**

1. **Receives Requests** – Acts as a traffic cop, routing client requests (e.g., HTTP, TCP, UDP) to servers.
2. **Distributes Traffic** – Uses algorithms (e.g., Round Robin, Least Connections, IP Hash) to decide which server should handle each request.
3. **Ensures High Availability** – Monitors server health and stops sending traffic to failed servers.
4. **Improves Performance** – Reduces server load, prevents downtime, and speeds up responses.

### **Types of Load Balancers:**

1. **Hardware Load Balancer** – Physical devices (e.g., F5 BIG-IP, Citrix ADC).
2. **Software Load Balancer** – Runs on virtual machines or containers (e.g., NGINX, HAProxy, AWS ALB).
3. **Cloud-Based Load Balancer** – Managed services like AWS ELB, Azure Load Balancer, Google Cloud Load Balancing.

### **Common Load Balancing Algorithms:**

- **Round Robin** – Distributes requests sequentially.
- **Least Connections** – Sends traffic to the server with the fewest active connections.
- **IP Hash** – Directs requests from the same IP to the same server (useful for session persistence).
- **Weighted Distribution** – Assigns traffic based on server capacity.

### **Benefits of Load Balancing:**

✔ **Scalability** – Handles increased traffic by adding more servers.  
✔ **Fault Tolerance** – Redirects traffic if a server fails.  
✔ **Reduced Downtime** – Enables zero-downtime maintenance (rolling updates).  
✔ **Improved Performance** – Distributes workload efficiently.

### **Use Cases:**

- **Web Applications** – Balancing HTTP/HTTPS traffic across web servers.
- **Databases** – Distributing read queries across replicas.
- **Microservices** – Routing API requests to different service instances.
- **Global Server Load Balancing (GSLB)** – Directing users to the nearest data center (CDN-like behavior).

---

### **Simple Example of a Load Balancer**

Imagine a **pizza delivery service** with multiple chefs (servers) and one manager (load balancer).

#### **Without a Load Balancer:**

- Customers (requests) call the restaurant directly.
- If all orders go to **Chef A**, he gets overwhelmed while **Chef B** sits idle.
- Some customers get their pizza late, and some orders may be lost if Chef A crashes.

#### **With a Load Balancer:**

1. Customers call the **manager (load balancer)** instead of the chefs directly.
2. The manager assigns orders in a balanced way:
   - First order → **Chef A**
   - Second order → **Chef B**
   - Third order → **Chef A**
   - And so on...
3. If **Chef B** gets sick (server fails), the manager stops sending orders to him.
4. New chefs (scaling up) can be added easily, and the manager will include them in the rotation.

### **Real-World Tech Example:**

- **Website Traffic:**
  - 3 web servers host the same site.
  - The load balancer (e.g., **NGINX**) distributes visitors evenly:
    - User 1 → Server 1
    - User 2 → Server 2
    - User 3 → Server 3
    - User 4 → Server 1
  - If **Server 2** crashes, the load balancer sends all traffic to Servers 1 & 3.

### **Key Takeaway:**

A load balancer ensures **no single server is overloaded**, improves **speed**, and keeps the system **reliable** even if one server fails.
